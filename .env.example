# Local model setup (Ollama)
MODEL_PROVIDER=ollama
OLLAMA_BASE_URL=http://localhost:11434
# OLLAMA_MODEL=llama3.1:8b # Tool-calling isn't great, but 5GB size is quite lightweight
OLLAMA_MODEL=qwen3:14b # Tool-calling is better, and 9GB size is more accessible
# OLLAMA_MODEL=gpt-oss:20b # Robust tool-calling, but 14GB size is restrictive

# Local embeddings
# EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2 # very lightweight
# EMBEDDING_DIM=384
EMBEDDING_MODEL=BAAI/bge-large-en-v1.5 # good middle-ground
EMBEDDING_DIM=1024
# EMBEDDING_MODEL=BAAI/bge-m3 # more powerful, but too large
# EMBEDDING_DIM=1024

# Paths
DATA_DIR=./data/raw
PROCESSED_DIR=./data/processed
VECTORSTORE_DIR=./data/processed/vectorstore

# Retrieval & Tooling
MAX_CONTEXT_DOCS=20
MAX_DOCS_PER_RETRIEVER=20
ENABLE_TOOL_CALLING=1
PREFER_STRUCTURED=0
 